# TinkerScript Design Blueprint / TinkerScript è®¾è®¡è“å›¾

[English](#english-version) | [ä¸­æ–‡](#chinese-version)

---

<a id="english-version"></a>
## ğŸ‡¬ğŸ‡§ English Version

### 1. Overview
**TinkerScript** is an experimental component of AgentJet designed to decouple the **Training Logic** from the **Agent Execution Logic**. It allows users to train **full-weight LLM models** on machines without GPUs (e.g., a laptop) by offloading the actual model computation to a remote GPU server.

Unlike traditional setups where the user code must run inside the training cluster, TinkerScript allows you to verify and run your agent logic locally while the heavy lifting (training & inference) happens remotely.

### 2. Core Architecture

The system involves two main parties: the **TinkerScript Server** (running on the GPU cluster) and the **TinkerScript Client** (running on your local machine).

```mermaid
graph TD
    subgraph "GPU Cluster (Server Side)"
        TrainingLoop["Training Loop (AgentJet/GRPO)"]
        TSS["TinkerScript Server (FastAPI)"]
        ZMQ["ZeroMQ / IPC"]
        SharedMem[("Shared Memory")]
        LLM["LLM Engine (vLLM/SGLang)"]
    end

    subgraph "User Laptop / CPU Cluster (Client Side)"
        UserScript["User Script (python while loop)"]
        AgentLogic["Agent Logic / Tools"]
    end

    TrainingLoop -- "1. Generate Task" --> SharedMem
    SharedMem -- "2. Register Episode" --> TSS

    UserScript -- "3. Claim Episode (HTTP)" --> TSS
    TSS -- "4. Return API Key & Base URL" --> UserScript

    UserScript -- "5. Inference (OpenAI API)" --> LLM
    LLM -- "Token Stream" --> UserScript

    UserScript -- "6. Submit Reward (HTTP)" --> TSS
    TSS -- "7. Push Result" --> ZMQ
    ZMQ -- "8. Update Weights" --> TrainingLoop
```

### 3. Detailed Workflow

The workflow relies on a "Claim & Submit" model. The training loop generates tasks ("Episodes") and waits for external workers to pick them up.

```mermaid
sequenceDiagram
    participant TL as Training Loop (Internal)
    participant S as Server (FastAPI)
    participant C as Client (User Script)
    participant M as LLM Model

    Note over TL, S: 1. Task Generation
    TL->>S: Register Episode (Status: Unclaimed)

    Note over C, S: 2. Task Acquisition
    loop Worker Loop
        C->>S: POST /claim_episode
        alt No Tasks
            S-->>C: Retry Later
        else Task Available
            S->>S: Mark as "Claimed"
            S-->>C: Return {EpisodeID, OpenAI_BaseURL, API_Key}
        end

        Note over C, M: 3. Execution (Rollout)
        C->>M: Chat Completion Request (Inference)
        M-->>C: Response (Generation)
        C->>C: Calculate Reward (e.g., Verify Math Answer)

        Note over C, S: 4. Result Submission
        C->>S: POST /end_episode {Reward, Metadata}
        S->>TL: Forward Result via ZeroMQ
        S->>S: Delete Episode Record (Complete)
    end
```

### 4. Episode State Machine

To handle network failures or client crashes, the server maintains a state machine for every episode.

```mermaid
stateDiagram-v2
    [*] --> Registered
    Registered --> Unclaimed_Queue : Add to Queue

    Unclaimed_Queue --> Claimed : Client requests task

    Claimed --> Completed : Client submits result
    Claimed --> Registered : Client Timeout / Crash

    Completed --> [*] : Removed from Memory
```

*   **Registered**: Task created by the training algorithm.
*   **Claimed**: A client is currently working on it.
*   **Timeout**: If a client claims a task but doesn't report back within `allow_discard_timeout`, the server reverts the status to **Registered** so another client can try.

### 5. Implementation Example

The user experience is designed to be minimal. You simply query the remote server for a "job", do the work, and report the "score".

```python
# User-side Code Concept
def rollout(task):
    # 1. Handshake & Claim (Get credentials for this specific episode)
    api_baseurl_key = tinkerjet_remote.begin_episode()

    # 2. Run your existing agent logic using standard OpenAI format
    workflow_output = execute_agent(task, api_baseurl_key)

    # 3. Submit results
    tinkerjet_remote.end_episode(workflow_output)
    return workflow_output.reward
```

### 6. Limitations

1.  **Strict OpenAI Protocol**: Users must use the OpenAI `base_url` + `api_key` pattern. Internal access (like direct model object access) is not available.
2.  **Implicit Multi-Agent Handling**: AgentJet cannot explicitly distinguish different agents in a multi-agent scenario via API, though it attempts to merge timeline shards automatically.
3.  **No Prompt Tuning**: TinkerScript is designed for full-weight model training, not for soft-prompt tuning.

---

<a id="chinese-version"></a>
## ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆæœ¬ (Chinese Version)

### 1. æ¦‚è¿° (Overview)
**TinkerScript** æ˜¯ AgentJet çš„ä¸€ä¸ªå®éªŒæ€§ç»„ä»¶ï¼Œæ—¨åœ¨å°† **è®­ç»ƒé€»è¾‘ (Training Logic)** ä¸ **Agent æ‰§è¡Œé€»è¾‘ (Execution Logic)** è§£è€¦ã€‚å®ƒå…è®¸ç”¨æˆ·åœ¨ **æ²¡æœ‰ GPU** çš„æœºå™¨ä¸Šï¼ˆä¾‹å¦‚æ™®é€šç¬”è®°æœ¬ç”µè„‘ï¼‰è®­ç»ƒ **å…¨å‚æ•° LLM æ¨¡å‹**ï¼Œè®¡ç®—å‹åŠ›å®Œå…¨ç”±è¿œç¨‹ GPU æœåŠ¡å™¨æ‰¿æ‹…ã€‚

ä¸ä¼ ç»Ÿçš„å°†ç”¨æˆ·ä»£ç åµŒå…¥è®­ç»ƒé›†ç¾¤çš„æ–¹å¼ä¸åŒï¼ŒTinkerScript å…è®¸ä½ åœ¨æœ¬åœ°è¿è¡Œå¹¶éªŒè¯ Agent é€»è¾‘ï¼Œé€šè¿‡ç½‘ç»œä¸è¿œç¨‹è®­ç»ƒå¾ªç¯äº¤äº’ã€‚

### 2. æ ¸å¿ƒæ¶æ„ (Core Architecture)

ç³»ç»ŸåŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šè¿è¡Œåœ¨ GPU é›†ç¾¤ä¸Šçš„ **TinkerScript Server** å’Œè¿è¡Œåœ¨æœ¬åœ°çš„ **TinkerScript Client**ã€‚

```mermaid
graph TD
    subgraph "GPU é›†ç¾¤ (Server ç«¯)"
        TrainingLoop["è®­ç»ƒå¾ªç¯ (AgentJet/GRPO)"]
        TSS["TinkerScript Server (FastAPI)"]
        ZMQ["ZeroMQ / IPC é€šä¿¡"]
        SharedMem[("å…±äº«å†…å­˜")]
        LLM["LLM æ¨ç†å¼•æ“ (vLLM/SGLang)"]
    end

    subgraph "ç”¨æˆ·ç¬”è®°æœ¬ / CPU é›†ç¾¤ (Client ç«¯)"
        UserScript["ç”¨æˆ·è„šæœ¬ (Python While Loop)"]
        AgentLogic["Agent ä¸šåŠ¡é€»è¾‘ / å·¥å…·è°ƒç”¨"]
    end

    TrainingLoop -- "1. ç”Ÿæˆä»»åŠ¡ (Task)" --> SharedMem
    SharedMem -- "2. æ³¨å†Œ Episode" --> TSS

    UserScript -- "3. é¢†å–ä»»åŠ¡ (HTTP Claim)" --> TSS
    TSS -- "4. è¿”å› API Key ä¸ Base URL" --> UserScript

    UserScript -- "5. æ¨ç†è¯·æ±‚ (OpenAI åè®®)" --> LLM
    LLM -- "ç”Ÿæˆ Token æµ" --> UserScript

    UserScript -- "6. æäº¤ Reward (HTTP End)" --> TSS
    TSS -- "7. æ¨é€ç»“æœ" --> ZMQ
    ZMQ -- "8. æ›´æ–°æƒé‡" --> TrainingLoop
```

### 3. è¯¦ç»†å·¥ä½œæµ (Detailed Workflow)

åŸºäºâ€œé¢†å– (Claim) - æäº¤ (Submit)â€æ¨¡å¼ã€‚è®­ç»ƒå¾ªç¯ç”Ÿæˆä»»åŠ¡ï¼ˆEpisodeï¼‰ï¼Œç­‰å¾…å¤–éƒ¨ Worker é¢†å–æ‰§è¡Œã€‚

```mermaid
sequenceDiagram
    participant TL as è®­ç»ƒå¾ªç¯ (å†…éƒ¨)
    participant S as Server (FastAPI)
    participant C as Client (ç”¨æˆ·è„šæœ¬)
    participant M as LLM æ¨¡å‹æœåŠ¡

    Note over TL, S: 1. ä»»åŠ¡ç”Ÿæˆé˜¶æ®µ
    TL->>S: æ³¨å†Œ Episode (çŠ¶æ€: Unclaimed)

    Note over C, S: 2. ä»»åŠ¡é¢†å–é˜¶æ®µ
    loop Worker Loop
        C->>S: POST /claim_episode (è¯·æ±‚ä»»åŠ¡)
        alt æ— å¯ç”¨ä»»åŠ¡
            S-->>C: è¯·ç¨åé‡è¯•
        else æœ‰å¯ç”¨ä»»åŠ¡
            S->>S: æ ‡è®°ä¸º "Claimed"
            S-->>C: è¿”å› {EpisodeID, OpenAI_BaseURL, API_Key}
        end

        Note over C, M: 3. æ‰§è¡Œé˜¶æ®µ (Rollout)
        C->>M: Chat Completion è¯·æ±‚ (æ¨ç†é€šè¿‡ç½‘ç»œå›ä¼ )
        M-->>C: è¿”å›ç”Ÿæˆç»“æœ
        C->>C: è®¡ç®— Reward (ä¾‹å¦‚: éªŒè¯æ•°å­¦ç­”æ¡ˆ)

        Note over C, S: 4. ç»“æœæäº¤é˜¶æ®µ
        C->>S: POST /end_episode {Reward, Metadata}
        S->>TL: é€šè¿‡ ZeroMQ è½¬å‘ç»“æœç»™è®­ç»ƒå™¨
        S->>S: åˆ é™¤ Episode è®°å½• (å®Œæˆ)
    end
```

### 4. çŠ¶æ€æœºç®¡ç† (Episode State Machine)

ä¸ºäº†å¤„ç†ç½‘ç»œæ³¢åŠ¨æˆ–å®¢æˆ·ç«¯å´©æºƒï¼ˆCrashï¼‰ï¼ŒæœåŠ¡ç«¯ä¸ºæ¯ä¸ª Episode ç»´æŠ¤äº†ä¸€ä¸ªçŠ¶æ€æœºã€‚

```mermaid
stateDiagram-v2
    [*] --> Registered (å·²æ³¨å†Œ)
    Registered --> Unclaimed_Queue : åŠ å…¥å¾…é¢†å–é˜Ÿåˆ—

    Unclaimed_Queue --> Claimed (å·²è¢«é¢†å–) : å®¢æˆ·ç«¯è¯·æ±‚ä»»åŠ¡

    Claimed --> Completed (å·²å®Œæˆ) : å®¢æˆ·ç«¯æäº¤ç»“æœ
    Claimed --> Registered (å·²æ³¨å†Œ) : å®¢æˆ·ç«¯è¶…æ—¶ / å´©æºƒ

    Completed --> [*] : ä»å†…å­˜ä¸­ç§»é™¤
```

*   **Registered (å·²æ³¨å†Œ)**: è®­ç»ƒç®—æ³•ç”Ÿæˆäº†è¯¥ä»»åŠ¡ï¼Œç­‰å¾…è¢«æ‰§è¡Œã€‚
*   **Claimed (å·²è¢«é¢†å–)**: æŸä¸ª Client æ­£åœ¨å¤„ç†è¯¥ä»»åŠ¡ã€‚
*   **Timeout (è¶…æ—¶)**: å¦‚æœ Client é¢†å–ä»»åŠ¡ååœ¨è§„å®šæ—¶é—´ (`allow_discard_timeout`) å†…æœªæäº¤ç»“æœï¼ŒæœåŠ¡å™¨ä¼šå°†çŠ¶æ€é‡ç½®ä¸º **Registered**ï¼Œå…è®¸å…¶ä»– Client é‡æ–°é¢†å–è¯¥ä»»åŠ¡ï¼ˆå®¹é”™æœºåˆ¶ï¼‰ã€‚

### 5. å®ç°ä»£ç ç¤ºä¾‹

ç”¨æˆ·ä¾§çš„ä»£ç éå¸¸ç®€æ´ã€‚ç®€è€Œè¨€ä¹‹ï¼šå‘è¿œç¨‹æœåŠ¡å™¨è¦ä¸€ä¸ªâ€œæ´»å„¿â€ï¼Œå¹²å®Œæ´»ï¼Œä¸ŠæŠ¥â€œå¾—åˆ†â€ã€‚

```python
# ç”¨æˆ·ä¾§ä»£ç æ¦‚å¿µæ¼”ç¤º
def rollout(task):
    # 1. æ¡æ‰‹ & é¢†å–ä»»åŠ¡ (è·å–å½“å‰ Episode ä¸“å±çš„é‰´æƒä¿¡æ¯)
    api_baseurl_key = tinkerjet_remote.begin_episode()

    # 2. è¿è¡Œä½ ç°æœ‰çš„ Agent é€»è¾‘ (ä½¿ç”¨æ ‡å‡† OpenAI æ¥å£)
    workflow_output = execute_agent(task, api_baseurl_key)

    # 3. æäº¤ç»“æœ
    tinkerjet_remote.end_episode(workflow_output)
    return workflow_output.reward
```

### 6. å±€é™æ€§ (Limitations)

1.  **ä¸¥æ ¼ä¾èµ– OpenAI åè®®**: ç”¨æˆ·å¿…é¡»ä½¿ç”¨ OpenAI `base_url` + `api_key` çš„æ–¹å¼ä¸æ¨¡å‹äº¤äº’ã€‚æ— æ³•è·å–æ¨¡å‹å†…éƒ¨å¯¹è±¡ï¼ˆWeights/Gradientsï¼‰ã€‚
2.  **éšå¼å¤šæ™ºèƒ½ä½“å¤„ç†**: åœ¨å¤šæ™ºèƒ½ä½“ï¼ˆMulti-Agentï¼‰åœºæ™¯ä¸‹ï¼ŒAgentJet æ— æ³•é€šè¿‡ API æ˜¾å¼åŒºåˆ†ä¸åŒçš„ Agent è§’è‰²ï¼Œä½†åå°ä¼šå°è¯•è‡ªåŠ¨åˆå¹¶æ—¶é—´çº¿ç‰‡æ®µã€‚
3.  **ä¸æ”¯æŒ Prompt Tuning**: TinkerScript ä¸“ä¸ºå…¨é‡æ¨¡å‹å¾®è°ƒè®¾è®¡ï¼Œä¸æ”¯æŒ Soft-Prompt Tuning ç­‰è½»é‡çº§å¾®è°ƒã€‚
