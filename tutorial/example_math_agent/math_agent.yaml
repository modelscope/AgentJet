# ------------------ 主要配置 ------------------
astuner
  project_name: example_math_agent
  task_reader:
    type: huggingface_dat_repo # ✨✨✨✨ `env_service` or `dataset_file` or `huggingface_dat_repo`
    # 如果选择 `huggingface_dat_repo` 以下配置生效
    huggingface_dat_repo:
      dataset_path: '/mnt/data_cpfs/qingxu.fu/dataset/openai/gsm8k/main'
      training_split: "train"
      validation_split: "test"

  task_judge:
    # ✨✨✨✨ 编写并选择评价函数
    judge_protocol: astuner.task_judge.math_answer_as_judge->MathAnswerAsJudge

  model:
    # ✨✨✨✨ 设置待训练的模型
    path: /mnt/data_cpfs/model_cache/modelscope/hub/Qwen/Qwen/Qwen2___5-14B-Instruct

  rollout:
    agentscope_learn_protocol: "tutorial.example_math_agent.math_agent->ExampleMathLearn" # ✨✨✨✨ 编写并选择Agent
    temperature: 0.7
    max_env_worker: 64
    num_repeat: 4
    agent_madness_reward: 0.0
    tensor_model_parallel_size: 1
    max_num_seqs: 40
    multi_turn:
      max_sample_per_task: 4
    compute_madness_checklist:
      - "nonsense"
      - "wrong_toolcall"
    max_response_length_in_one_turn: 1024
    max_model_len: 13000

  data:
    train_batch_size: 264
    max_prompt_length: 3000
    max_response_length: 10000

  debug:
    debug_max_parallel: 1
    debug_first_n_tasks: 1

  trainer_common:
    save_freq: 99999
    test_freq: 99999
    total_epochs: 99999
    trinity_only__n_vllm_engine: 2  # must be division by tensor_model_parallel_size


trinity:
  trainer:
    max_token_len_per_gpu: 13000



# ------------------ 不需要修改 ------------------
hydra:
  searchpath:
    - file://astuner/default_config
    - file://astuner/default_config/verl         # verl only
    - file://external/verl/verl/trainer/config  # verl only
    - file://astuner/default_config/trinity      # trinity only

# ------------------ 不需要修改 ------------------
defaults:
  - ppo_trainer # verl inherit 1/2
  - verl_default # verl inherit 2/2
  - trinity_default # trinity inherit 1/1
  - astune_default
  - _self_
