trainer:
  val_before_train: False
  hfmodelpath: ""
  experiment_name: "read_yaml_name"
  n_gpus_per_node: 8
  nnodes: 1
  save_freq: 20
  test_freq: 20
  total_epochs: 50
  project_name: appworldnew
  critic_warmup: 0
  val_pass_n: 4
  logger:
    - console
    - swanlab

data:
  val_batch_size: 100000000000
  return_raw_chat: True
  filter_overlong_prompts: True
  truncation: error
  fast_eval: True

algorithm:
  task_norm_patch: False
  adv_estimator: grpo
  use_kl_in_reward: False

actor_rollout_ref:
  hybrid_engine: True
  actor:
    entropy_coeff: 0
    loss_agg_mode: seq-mean-token-mean
    override_ppo_mini_batch_num: 1
    ppo_epochs: 1
    ppo_mini_batch_size: 16
    optim:
      lr: 1e-6
    use_kl_loss: True
    kl_loss_coef: 0.002
    kl_loss_type: low_var_kl
    ppo_micro_batch_size_per_gpu: 1
    ppo_max_token_len_per_gpu: 18000
    use_dynamic_bsz: True
    fsdp_config:
      param_offload: True
      optimizer_offload: True

  rollout:
    name: vllm
    mode: async
    max_env_len: 3000
    ppo_micro_batch_size_per_gpu: 1
    tensor_model_parallel_size: 1
    max_num_seqs: 10
    gpu_memory_utilization: 0.9
    max_env_worker: 64
    log_prob_max_token_len_per_gpu: 18000
    temperature: 0.9
    top_p: 1.0
    gamma: 1.0
    enforce_eager: True
    log_prob_micro_batch_size_per_gpu: 4
    custom_dataflow_cls:
      path: ""
      name: ""

  ref:
    use_dynamic_bsz: True
    log_prob_micro_batch_size_per_gpu: 4
    log_prob_max_token_len_per_gpu: 18000
    fsdp_config:
      param_offload: True

  model:
    use_remove_padding: True
    enable_gradient_checkpointing: True
